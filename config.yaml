# Training configuration for train_qLora.py
# You can edit this file to change defaults without passing CLI flags.

base_model: meta-llama/Llama-3.1-8B
tiny_debug_model: TinyLlama/TinyLlama-1.1B-Chat-v1.0

lora:
  r: 8
  alpha: 32
  dropout: 0.05

learning_rate: 0.0002
batch_size: 4
grad_accum: 16
max_seq_len: 512
epochs: 3
save_dir: ./lora_out
seed: 42

# Optional: steps-based control and validation split
# Set max_steps to a positive number to override epochs; keep -1 to use epochs
max_steps: -1
val_split: 0.1

# Data sources (choose one)
# 1) Local JSONL dataset (default)
dataset: sample_dataset.jsonl
# 2) Parquet path produced by datasets_logic/preprocessing scripts
parquet_path: data/coedit_parquet/coedit_train.parquet
# 3) Hugging Face dataset id and split (e.g., "grammarly/coedit")
hf_dataset: null
hf_split: train
# Optional filter for CoEdIT-like datasets: only keep rows with matching task (e.g., "gec")
coedit_task: null

# Runtime
device_map: auto  # e.g., "auto", "cpu"
quantization: bnb_8bit  # one of: auto, bnb_4bit, bnb_8bit, none
resume_from_checkpoint: ./lora_out/checkpoint-800 # none
debug_tiny: false
bf16: false # makes no difference on rtx 3090, but I'd have to retrain.
attn_implementation: flash_attention_2  # e.g., null, eager, sdpa, flash_attention_2, flash_attention_3

# Logging / evaluation / saving
log_level: INFO
logging_steps: 10
evaluation_strategy: steps
eval_steps: 100
save_steps: 100
save_total_limit: 2
report_to: []  # e.g., ["wandb"]

# Evaluation controls
max_generated: 50

# Training target formatting
# One of: good_only (default) or structured (Span/Suggestion/Rationale block)
train_target_format: good_only

# Training direction: 'fixer' (bad->good) or 'degrader' (good->bad)
train_direction: degrader

# CometML experiment tracking (for eval loops during training)
comet:
  enabled: false           # set true to enable Comet logging
  project_name: doc-qa-reducer       # e.g., "doc-qa-reducer"
  workspace: null          # your Comet workspace (optional)
  api_key: null            # optional; can also use env COMET_API_KEY
  offline: false           # set true to log offline and upload later
  eval_samples: 8          # how many eval samples to log each eval step
  gen_max_new_tokens: 128  # generation length for predictions